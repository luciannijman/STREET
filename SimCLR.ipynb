{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Loaded 52 images.\n",
      "Training SimCLR model...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# SimCLR Augmentation function\n",
    "def simclr_augment(image):\n",
    "    image = tf.cast(image, tf.float32)  # Cast to float32\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_crop(image, size=[int(image.shape[0] * 0.9), int(image.shape[1] * 0.9), 3])\n",
    "    image = tf.image.resize(image, [224, 224])  # Resizing to target size\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Load all images from a directory, including subdirectories\n",
    "def load_images_from_directory(data_dir, image_size=(224, 224)):\n",
    "    image_list = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image file extensions\n",
    "                try:\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    img = Image.open(img_path).convert(\"RGB\")  # Ensure 3-channel RGB\n",
    "                    img = img.resize(image_size)  # Resize to target size\n",
    "                    img = np.array(img) / 255.0  # Normalize pixel values\n",
    "                    image_list.append(img.astype(np.float32))  # Convert to float32\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {file}: {e}\")\n",
    "    return np.array(image_list, dtype=np.float32)  # Ensure entire dataset is float32\n",
    "\n",
    "\n",
    "# Build the SimCLR model\n",
    "def build_simclr_model(input_shape=(224, 224, 3), projection_dim=128):\n",
    "    # Base encoder: ResNet50\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # Projection head\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    outputs = layers.Dense(projection_dim)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Contrastive loss function\n",
    "def nt_xent_loss(z_i, z_j, temperature=0.5):\n",
    "    z_i = tf.math.l2_normalize(z_i, axis=1)\n",
    "    z_j = tf.math.l2_normalize(z_j, axis=1)\n",
    "    \n",
    "    # Concatenate positive pairs\n",
    "    z = tf.concat([z_i, z_j], axis=0)\n",
    "    similarity_matrix = tf.matmul(z, z, transpose_b=True) / temperature\n",
    "\n",
    "    # Create labels\n",
    "    batch_size = tf.shape(z_i)[0]\n",
    "    labels = tf.one_hot(tf.range(batch_size), depth=2 * batch_size)\n",
    "    labels = tf.concat([labels, labels], axis=0)\n",
    "\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, similarity_matrix)\n",
    "    return loss\n",
    "\n",
    "# Train SimCLR model\n",
    "def train_simclr(image_data, epochs=10, batch_size=32):\n",
    "    model = build_simclr_model()\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "    # Cast images to float32 and create TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tf.cast(image_data, tf.float32))\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_data)).batch(batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = []\n",
    "        for batch in dataset:\n",
    "            # Create augmented views\n",
    "            augmented_images_1 = tf.map_fn(simclr_augment, batch)\n",
    "            augmented_images_2 = tf.map_fn(simclr_augment, batch)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                z_i = model(augmented_images_1, training=True)\n",
    "                z_j = model(augmented_images_2, training=True)\n",
    "                loss = nt_xent_loss(z_i, z_j)\n",
    "            \n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            epoch_loss.append(loss.numpy())\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {np.mean(epoch_loss)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Extract embeddings from the trained model\n",
    "def extract_embeddings(model, image_data, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_data).batch(batch_size)\n",
    "    embeddings = []\n",
    "    for batch in dataset:\n",
    "        embeddings_batch = model(batch, training=False).numpy()\n",
    "        embeddings.append(embeddings_batch)\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# Main function to run SimCLR\n",
    "def main():\n",
    "    data_dir = \"London_UK/images\" #Path to images folder (Use test images folder)\n",
    "    print(\"Loading images...\")\n",
    "    image_data = load_images_from_directory(data_dir)\n",
    "    print(f\"Loaded {len(image_data)} images.\")\n",
    "    \n",
    "    print(\"Training SimCLR model...\")\n",
    "    model = train_simclr(image_data, epochs=10, batch_size=32)\n",
    "\n",
    "    print(\"Extracting embeddings...\")\n",
    "    embeddings = extract_embeddings(model, image_data)\n",
    "    print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
